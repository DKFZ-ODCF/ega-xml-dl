#!/bin/bash

# count lines in a file, returning ONLY the numeric count 
linecount() {
  wc -l "$1" | cut -d' ' -f1
}

todo_for() {
    echo "$OUTPUT_DIR/todo-$1.txt"
}



# Login Information for EGA
# TODO: make sure cmd input is KeePass compatible (tab separated)

if [ -z $1 ]; then # see if box was specified on command line
  read -p "From which box do you wish to download? ega-box-" BOX_NR
  BOX="ega-box-$BOX_NR"
else
  BOX="$1"
fi
# get password
read -p "password for $BOX? (ctrl+shift+v to paste) " -s PASSWORD
echo 


# timestamp so we can 'version' our data
DATE=$(date '+%Y-%m-%d')

# where to put our batch downloads
OUTPUT_DIR="$HOME/ega-xml/$BOX";
echo "Outputting downloads to $OUTPUT_DIR"

if [ ! -d "$OUTPUT_DIR" ]; then mkdir -p "$OUTPUT_DIR"; fi;


###################################
# STEP 1: grab list of todo's

# Regex to extract individual items from HTML overview pages
# matches both EGA ("EGA") and ENA ("ER") ID's
# following the arachive identifier, a letter identifies the type of data, then a number the item
# EGA: Z=analysis, X=eXperiment, R=Run, N=sample, S=Study, D=Dataset, '<blank>'=Submission, C=daCs
# ENA:             X=eXperiment, R=Run, S=Sample, P=study/Project, A=Submission
ITEM_PATTERN="https://www.ebi.ac.uk/ena/submit/drop-box/[^/]+/((EGA|ER)[ZXRNSCPDA]?\d+)\?format=html"

# for each of the raw data-types of EGA
# note, TYPE-strings match EGA-API as-is (including spelling errors), do not "fix", or you'll get errors
# skip 'project' and 'policys', as there is no content there via this format.
TYPES=('analyses' 'experiments' 'runs' 'samples' 'studies' 'submissions' 'dacs' 'datasets')
for TYPE in "${TYPES[@]}"; do
    echo "preparing todo-list for $TYPE"
    # construct the overview URL
    URL="https://www.ebi.ac.uk/ena/submit/drop-box/$TYPE"

    # unfortunately, there is no way to use recursive wget, because the EBI does not offer
    # any listing of all the XML files (even requesting the overview with "format=xml" does nothing
    #
    # WORKAROUND:
    #   1) wget: get the overview list
    #   2) grep: extract only the links to listed files
    #   3) sed:  convert the links to point at the XML result, instead of HTML
    #   4) store as a batch file of URLs, for a second wget invocation
    wget \
         --no-verbose \
         --user-agent="DKFZ ega crawler - odcf-service@dkfz-heidelberg.de" \
         --user="$BOX" --password="$PASSWORD" \
         --output-document='-' $URL \
         | grep --perl-regexp --only-matching "$ITEM_PATTERN" \
         | sed 's/format=html/format=xml/' \
         > "$( todo_for $TYPE )"

done

echo "done preparing ToDo lists, now getting files"

for TYPE in "${TYPES[@]}"; do
    TYPE_DIR="$OUTPUT_DIR/$TYPE"
    TODO="$( todo_for $TYPE )"

    # store all XML files per analysis type
    if [ ! -d "$TYPE_DIR" ]; then mkdir "$TYPE_DIR"; fi;
    cd "$TYPE_DIR"

    ###################################
	# STEP 2A: filter what we already have, if any

    echo "checking $TYPE for pre-existing downloads"
    echo "   unfiltered ToDo-list has $( linecount "$TODO" ) items"

    HAVE="$OUTPUT_DIR/already-have-$TYPE.txt"

    # look for files already having a complete closing marker
    #   because the EBI sends pretty-printed (indented) XML, 
    #   closing marker at start-of-line means that the file is complete
    grep -El "^</.+>$" EGA*?format=xml ER*?format=xml > "$HAVE"

    # remove all file-names in already-have from todo
    grep -vFf "$HAVE" "$TODO" > "$OUTPUT_DIR/tmp-$TYPE.txt"
    mv "$OUTPUT_DIR/tmp-$TYPE.txt" "$TODO"
    echo "   removed $( linecount "$HAVE" ) previously downloaded items, $( linecount "$TODO" ) remaining"
    rm "$HAVE"

    ###################################
    # STEP 2B: actually get stuff
    echo "processing $TODO ($( linecount "$TODO" ) items)"

    # get batch of XML files for this data-type
    wget \
         --no-verbose \
         --limit-rate=2M \
         --continue \
         --user-agent="DKFZ ega crawler" \
         --user="$BOX" --password="$PASSWORD" \
         --input-file "$TODO"

    rm "$TODO"
done

echo "DONE: got data for all types!"
